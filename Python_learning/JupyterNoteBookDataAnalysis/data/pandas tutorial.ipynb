{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importing key modules\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  df=pd.read_csv('data/public.csv') #reading csv files\n",
    "\n",
    "df=pd.read_csv('data/public.csv', index_col='Respondent') \n",
    "#reading csv and setting index as a specific column\n",
    "#schema_df = pd.read_csv('data/schema.csv')\n",
    "\n",
    "schema_df = pd.read_csv('data/schema.csv', index_col='Column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',85) #set the display\n",
    "pd.set_option('display.max_rows',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df #show the datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # shape of data frame: size (rows, colomns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10) #first n rows, defaut 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() #last n rows, defaut 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #getting informations for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hobbyist'] #calling a column with name 'Hobbyist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hobbyist'].value_counts() #counting values of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1,'Hobbyist'] #calling value, .loc[index(row), column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:3,'MainBranch':'EduOther'] \n",
    "#calling with slide method, note that it is inclusive of the end value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1] #this is the 1st respondent, iloc[0], as we set index_col = 'Respondent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df.loc['MgrIdiot'] #locate row with new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df.loc['MgrIdiot','QuestionText'] \n",
    "#locate entry with row index = 'MgrIdiot' and column index = 'QuestionText'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df.sort_index(inplace=True) \n",
    "#sorting index, default is ascending alphabetical, need inplace = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df.sort_index(ascending=False) #sorting index, descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_salary = (df['ConvertedComp']>70000) # a filter of salary > 70000\n",
    "df.loc[high_salary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[high_salary, ['Country','Ethnicity','ConvertedComp']] #show the filter and also the columes we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['United States', 'China'] # a list of countries\n",
    "filt = df['Country'].isin(countries) #'isin' tells if something is in a list \n",
    "df.loc[filt,'Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LanguageWorkedWith'] \n",
    "filt2 = df['LanguageWorkedWith'].str.contains('Python', na=False) \n",
    "# if keyword 'Python' is in the string and making NaN not count\n",
    "df.loc[filt2, ['Country','ConvertedComp','LanguageWorkedWith']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'ConvertedComp':'SalaryUSD'}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hobbyist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hobbyist'].replace({'Yes':True, 'No':False}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hobbyist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Country','SalaryUSD'], ascending=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalaryUSD'].nlargest(10) # nlargest can only deal with numbers, shows first n largest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nlargest(10,'SalaryUSD') # shows the entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nsmallest(10, 'SalaryUSD') # nlargest and nsmallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalaryUSD'].median() # finding the median of a series(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median() # automatically finding the ones that have numerical input, return a median for each (True ==1, False==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # describe() can give some statistical values on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalaryUSD'].count() # counting non-NaN values, use count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hobbyist'].value_counts() # counting different values, use value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SocialMedia'].value_counts() # counting interesting values of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SocialMedia'].value_counts(normalize=True) # the argument normalize=True makes the value count into percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: try to figure out what social media is the most favorite in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'].value_counts() # 1. find out the most responded countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp = df.groupby(['Country']) #get a dataframe that is regrouped by a list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp.get_group('United States') # get the dataframe that is the group of 'United States'\n",
    "# note that if we only care about one country, we can also use:\n",
    "# filt = df['Country']=='United States'\n",
    "# df.loc[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp['SocialMedia'].value_counts().head(50) # show the value counts of column 'SocialMedia', show the first 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp['SocialMedia'].value_counts().loc['United States'] # using the previous grouped dataframe to locate\n",
    "# don't have to run filter every time now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp['SocialMedia'].value_counts(normalize=True).loc['China']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp['SocialMedia'].value_counts().loc['Russian Federation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp['SalaryUSD'].median() # finding the median, but grouped by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp['SalaryUSD'].median().loc['United States'] - country_grp['SalaryUSD'].median().loc['China'] #show a difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp['SalaryUSD'].agg(['mean','median','std']) # use .agg to pass in functions we want, mean, median, standard deviation\n",
    "# note the [] indicate we are passing in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp['SalaryUSD'].agg(['mean','median','std']).loc['Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: to see how many people knows Python, by country\n",
    "\n",
    "filt = df['Country']=='United States'\n",
    "df[filt]['LanguageWorkedWith'].str.contains('Python').sum()\n",
    "\n",
    "# str.contains() is a function to check if(return True) or not(return False) a string contains a specific string.\n",
    "# sum() is adding, can add True as 1 and False as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the grouped dataframe, the correct way: use .apply()\n",
    "\n",
    "country_grp['LanguageWorkedWith'].apply( lambda x: x.str.contains('Python').sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_grp['LanguageWorkedWith'].apply( lambda x: x.str.contains('Python').sum() ).loc['United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: what percentage of developers in each country knows Python?\n",
    "\n",
    "# step 1: find respondent in each country:\n",
    "\n",
    "country_respondent = df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: find respondent who knows 'Python':\n",
    "python_by_country = country_grp['LanguageWorkedWith'].apply( lambda x: x.str.contains('Python').sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: concatinate 2 series together:\n",
    "python_df = pd.concat([country_respondent,python_by_country], axis='columns', sort=False)\n",
    "# concat() default axis is row, but we want to match the column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df.rename(columns={'Country':'num_total_respondent','LanguageWorkedWith':'num_know_Python'}, inplace = True)\n",
    "# cleaning up the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: calculate the percentage and assign it to a new column: (use * 100 to make it easier to read)\n",
    "python_df['percentage_know_Python_(100%)'] = (python_df['num_know_Python']/python_df['num_total_respondent']) * 100\n",
    "python_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now play with it a bit\n",
    "\n",
    "python_df.sort_values(by=['percentage_know_Python_(100%)'], ascending = False, inplace = True) #sort by descending order\n",
    "\n",
    "filt = python_df['num_total_respondent'] > 100 # filter with respondent number greater than 100, more meaningful\n",
    "\n",
    "python_df[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing custom missing values into np.nan when reading csv\n",
    "NA_val = ['NA','Missing'] # common custom missing values\n",
    "\n",
    "dfnna = pd.read_csv('data/public.csv', index_col='Respondent', na_values=NA_val) # replace with np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the average years of coding?\n",
    "# step 1. check if every entry is float\n",
    "df['YearsCode'].unique() # check the possible values, note the dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take care of the abnormal entries based on experience and judgment\n",
    "df['YearsCode'].replace('Less than 1 year', 0, inplace=True)\n",
    "df['YearsCode'].replace('More than 50 years', 51, inplace=True)\n",
    "# step 2. change dtype to float\n",
    "df['YearsCode']=df['YearsCode'].astype(float)\n",
    "# step 3. find the average\n",
    "df['YearsCode'].agg(['mean','median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt = pd.read_csv('data/ETH_1h.csv') # the date time data example\n",
    "df_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the current Date column is not in pandas datetime setting.\n",
    "# use pd.to_datetime to format, and the format is comparing the data, namely labeling your data with the info it represents.\n",
    "# %Y is years, %m is month, %d is day, %I is hours(24), %p is makeing sure am/pm is taken care of.\n",
    "df_dt['Date'] = pd.to_datetime(df_dt['Date'], format='%Y-%m-%d %I-%p')\n",
    "df_dt['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt.loc[0,'Date'].day_name() # see which day of the week a datetime data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to parse the datetime at the beginning when reading .csv:\n",
    "\n",
    "d_parser = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %I-%p') \n",
    "# a function we defined, x is a string, and pd.datetime.strptime(x, 'formating')\n",
    "\n",
    "df_dt=pd.read_csv('data/ETH_1h.csv', parse_dates=['Date'], date_parser=d_parser)\n",
    "# the keywords parse_dates represents the column we wish to parse, and date_parser is how we want to change it.\n",
    "\n",
    "df_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt['Date'].dt.day_name() # the .dt method makes .day_name() apply to the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "df_dt['Date'].min(),\n",
    "df_dt['Date'].max(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt['Date'].min()-df_dt['Date'].max() # to find the number of date between, use subtract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt.loc[0,'Date']-df_dt.loc[2000, 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = df_dt['Date'] >= '2020' # pass in a filter making years later than 2020.\n",
    "df_dt[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df_dt['Date'] > '2019')& (df_dt['Date'] < '2020')  # pass in a filter making years later than 2019 and before 2020.\n",
    "df_dt[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df_dt['Date'] > pd.to_datetime('2019-01-01'))& (df_dt['Date'] < pd.to_datetime('2020-01-01'))  \n",
    "# pass in a filter making the datetime later than 2019-01-01 and before 2020-01-01.\n",
    "df_dt[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt.set_index('Date', inplace = True) # setting the Date as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt['2019'] # we can access date time by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt['2020-01':'2020-02'] # sliding, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some analysis: \n",
    "# 1. average closing price:\n",
    "df_dt['2020-01':'2020-02']['Close'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. a high value of a specific date: since data is given in hours, the highest of the day is the max of all hourly highs.\n",
    "df_dt['2020-01-01']['High'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. resample the data by days (default in hours):\n",
    "df_dt['High'].resample('D').max() # take the max value as resample representative\n",
    "# resample by D(ay). other valid inputs: 1D, 2D, W(eek), M(onth), Q(uarter), Y(ear), ...\n",
    "# see http://bit.ly/pandas-dt-fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Highs_day = df_dt['High'].resample('D').max()\n",
    "Highs_day['2020-01-01'] # compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt # a ploting exercise.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Highs_day.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. resample multiple columns: max of high, min of low, sum of volume, on a weekly basis\n",
    "dictionary = {'High':'max', 'Low': 'min', 'Volume': 'sum'}\n",
    "df_dt.resample('W').agg(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. plot it together\n",
    "H_L_V = df_dt.resample('W').agg(dictionary)\n",
    "H_L_V[['High','Low']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
